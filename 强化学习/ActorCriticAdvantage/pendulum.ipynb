{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from actor import Actor\n",
    "from critic import Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPISODE = 1000\n",
    "MAX_EP_STEPS = 200\n",
    "DISPLAY_REWARD_THRESHOLD = -100\n",
    "RENDER = False\n",
    "LR_A = 0.001\n",
    "LR_C = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Pendulum-v0')\n",
    "env = env.unwrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_S = env.observation_space.shape[0]\n",
    "A_BOUND = env.action_space.high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = Actor(n_features=N_S, lr=LR_A, action_bound=[float(-A_BOUND), float(A_BOUND)])\n",
    "critic = Critic(n_features=N_S, lr=LR_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  0   reward: -115\n",
      "episode:  1   reward: -120\n",
      "episode:  2   reward: -119\n",
      "episode:  3   reward: -121\n",
      "episode:  4   reward: -119\n",
      "episode:  5   reward: -120\n",
      "episode:  6   reward: -118\n",
      "episode:  7   reward: -121\n",
      "episode:  8   reward: -119\n",
      "episode:  9   reward: -122\n",
      "episode:  10   reward: -120\n",
      "episode:  11   reward: -118\n",
      "episode:  12   reward: -122\n",
      "episode:  13   reward: -125\n",
      "episode:  14   reward: -126\n",
      "episode:  15   reward: -129\n",
      "episode:  16   reward: -129\n",
      "episode:  17   reward: -134\n",
      "episode:  18   reward: -130\n",
      "episode:  19   reward: -129\n",
      "episode:  20   reward: -125\n",
      "episode:  21   reward: -127\n",
      "episode:  22   reward: -123\n",
      "episode:  23   reward: -126\n",
      "episode:  24   reward: -130\n",
      "episode:  25   reward: -126\n",
      "episode:  26   reward: -128\n",
      "episode:  27   reward: -128\n",
      "episode:  28   reward: -129\n",
      "episode:  29   reward: -129\n",
      "episode:  30   reward: -133\n",
      "episode:  31   reward: -136\n",
      "episode:  32   reward: -132\n",
      "episode:  33   reward: -133\n",
      "episode:  34   reward: -131\n",
      "episode:  35   reward: -128\n",
      "episode:  36   reward: -131\n",
      "episode:  37   reward: -127\n",
      "episode:  38   reward: -125\n",
      "episode:  39   reward: -124\n",
      "episode:  40   reward: -122\n",
      "episode:  41   reward: -120\n",
      "episode:  42   reward: -118\n",
      "episode:  43   reward: -115\n",
      "episode:  44   reward: -116\n",
      "episode:  45   reward: -114\n",
      "episode:  46   reward: -115\n",
      "episode:  47   reward: -114\n",
      "episode:  48   reward: -113\n",
      "episode:  49   reward: -115\n",
      "episode:  50   reward: -113\n",
      "episode:  51   reward: -112\n",
      "episode:  52   reward: -113\n",
      "episode:  53   reward: -114\n",
      "episode:  54   reward: -114\n",
      "episode:  55   reward: -115\n",
      "episode:  56   reward: -113\n",
      "episode:  57   reward: -116\n",
      "episode:  58   reward: -116\n",
      "episode:  59   reward: -116\n",
      "episode:  60   reward: -119\n",
      "episode:  61   reward: -122\n",
      "episode:  62   reward: -123\n",
      "episode:  63   reward: -125\n",
      "episode:  64   reward: -122\n",
      "episode:  65   reward: -124\n",
      "episode:  66   reward: -124\n",
      "episode:  67   reward: -122\n",
      "episode:  68   reward: -120\n",
      "episode:  69   reward: -117\n",
      "episode:  70   reward: -118\n",
      "episode:  71   reward: -120\n",
      "episode:  72   reward: -122\n",
      "episode:  73   reward: -120\n",
      "episode:  74   reward: -122\n",
      "episode:  75   reward: -119\n",
      "episode:  76   reward: -117\n",
      "episode:  77   reward: -115\n",
      "episode:  78   reward: -113\n",
      "episode:  79   reward: -115\n",
      "episode:  80   reward: -113\n",
      "episode:  81   reward: -113\n",
      "episode:  82   reward: -112\n",
      "episode:  83   reward: -110\n",
      "episode:  84   reward: -110\n",
      "episode:  85   reward: -112\n",
      "episode:  86   reward: -115\n",
      "episode:  87   reward: -111\n",
      "episode:  88   reward: -113\n",
      "episode:  89   reward: -116\n",
      "episode:  90   reward: -116\n",
      "episode:  91   reward: -119\n",
      "episode:  92   reward: -119\n",
      "episode:  93   reward: -117\n",
      "episode:  94   reward: -119\n",
      "episode:  95   reward: -117\n",
      "episode:  96   reward: -114\n",
      "episode:  97   reward: -113\n",
      "episode:  98   reward: -116\n",
      "episode:  99   reward: -115\n",
      "episode:  100   reward: -116\n",
      "episode:  101   reward: -118\n",
      "episode:  102   reward: -117\n",
      "episode:  103   reward: -115\n",
      "episode:  104   reward: -117\n",
      "episode:  105   reward: -117\n",
      "episode:  106   reward: -116\n",
      "episode:  107   reward: -120\n",
      "episode:  108   reward: -116\n",
      "episode:  109   reward: -120\n",
      "episode:  110   reward: -125\n",
      "episode:  111   reward: -126\n",
      "episode:  112   reward: -130\n",
      "episode:  113   reward: -130\n",
      "episode:  114   reward: -129\n",
      "episode:  115   reward: -127\n",
      "episode:  116   reward: -125\n",
      "episode:  117   reward: -124\n",
      "episode:  118   reward: -123\n",
      "episode:  119   reward: -121\n",
      "episode:  120   reward: -124\n",
      "episode:  121   reward: -121\n",
      "episode:  122   reward: -125\n",
      "episode:  123   reward: -123\n",
      "episode:  124   reward: -126\n",
      "episode:  125   reward: -124\n",
      "episode:  126   reward: -127\n",
      "episode:  127   reward: -130\n",
      "episode:  128   reward: -132\n",
      "episode:  129   reward: -130\n",
      "episode:  130   reward: -128\n",
      "episode:  131   reward: -129\n",
      "episode:  132   reward: -129\n",
      "episode:  133   reward: -130\n",
      "episode:  134   reward: -127\n",
      "episode:  135   reward: -128\n",
      "episode:  136   reward: -127\n",
      "episode:  137   reward: -127\n",
      "episode:  138   reward: -127\n",
      "episode:  139   reward: -125\n",
      "episode:  140   reward: -123\n",
      "episode:  141   reward: -121\n"
     ]
    }
   ],
   "source": [
    "for i_episode in range(MAX_EPISODE):\n",
    "\ts = env.reset()\n",
    "\tt = 0\n",
    "\tep_rs = []\n",
    "\twhile True:\n",
    "\t\tif RENDER: env.render()\n",
    "\t\ta = actor.choose_action(s)\n",
    "\n",
    "\t\ts_, r, done, info = env.step([a])\n",
    "\t\tr /= 10\n",
    "\n",
    "\t\ttd_error = critic.learn(s, r, s_)   # gradient = grad[r + gamma * V(s_) - V(s)]\n",
    "\t\tactor.learn(s, a, td_error)   # gradient = grad[logPi(s, a) * td_error]\n",
    "\n",
    "\t\ts = s_\n",
    "\t\tt += 1\n",
    "\t\tep_rs.append(r)\n",
    "\t\tif t > MAX_EP_STEPS:\n",
    "\t\t\tep_rs_sum = sum(ep_rs)\n",
    "\t\t\tif 'running_reward' not in globals():\n",
    "\t\t\t\trunning_reward = ep_rs_sum\n",
    "\t\t\telse:\n",
    "\t\t\t\trunning_reward = running_reward * 0.9 + ep_rs_sum * 0.1\n",
    "\t\t\tif running_reward > DISPLAY_REWARD_THRESHOLD: RENDER = True\n",
    "\t\t\tprint('episode: ', i_episode, '  reward:', int(running_reward))\n",
    "\t\t\tbreak\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "41012682a26ab7523e1c2229b30ca43de5762a175f7ae25c25f2d59b0d2e0e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
